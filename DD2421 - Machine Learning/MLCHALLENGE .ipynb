{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KSfEGjBEMh6",
        "outputId": "21dabf6a-0001-42cb-d719-653e673bd80a"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.externals import joblib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pre-processing and analyzing data (data was originally cleaned in excel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Loading in pre-processed data set\n",
        "df = pd.read_csv (r'/content/TrainOnMe-edited.csv')\n",
        "\n",
        "# Encoded values in data set\n",
        "# y = {0 : Shoogee, 1 : Bob, 2 : Jorg, 3 : Atsuto}\n",
        "# x12 = {0 : False, 1 : True}\n",
        "\n",
        "# Cleaning data and creating train/test sets\n",
        "df = pd.read_csv (r'/content/TrainOnMe-edited.csv')\n",
        "df = df.drop(df.tail(1).index) # Nan\n",
        "df = df.drop(841) # Corrupted data point left after pre-processing\n",
        "labels = df[\"y\"].values\n",
        "df = df.drop(columns=[\"Unnamed: 0\",\"y\"]) # Data cleaning\n",
        "df = df.drop(columns=['x1', 'x3', 'x7', 'x12', 'x13']) # Feature selection\n",
        "\n",
        "# Check balance of data set\n",
        "test = [0,0,0,0]\n",
        "for i in range(len(labels)):\n",
        " test[int(labels[i])] += 1\n",
        "print(test)\n",
        "# [290, 268, 340, 95]\n",
        "\n",
        "# Basic oversampling, use data of class 3 3x extra.\n",
        "X = []\n",
        "Y = []\n",
        "for i in range(len(labels)):\n",
        "  # print(df.values[i])\n",
        "  if int(labels[i]) == 3:\n",
        "    X.append(df.values[i])\n",
        "    X.append(df.values[i])\n",
        "    Y.append(labels[i])\n",
        "    Y.append(labels[i])\n",
        "  X.append(df.values[i])\n",
        "  Y.append(labels[i])\n",
        "# print(len(X))  # 1183\n",
        "# print(len(Y))  # 1183\n",
        "\n",
        "# Division into train/test set\n",
        "x_train = X[:900]\n",
        "x_test = X[900:]\n",
        "y_train = Y[:900]\n",
        "y_test = Y[900:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "df=(df - df.mean()) / df.std()\n",
        "pca = PCA(n_components=13)\n",
        "comps = pca.fit_transform(df)\n",
        "plt.plot(comps)\n",
        "loadings = pd.DataFrame(pca.components_.T,\n",
        "columns=['PC%s' % _ for _ in range(len(df.columns))],\n",
        "index=df.columns)\n",
        "plt.plot(pca.explained_variance_ratio_)\n",
        "plt.ylabel('Explained Variance')\n",
        "plt.xlabel('Components')\n",
        "plt.show()\n",
        "print(np.argmax(comps[:,4]))\n",
        "# Helped localize outlier : index 841"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Feature selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Features selection\n",
        "sel = SelectFromModel(RandomForestClassifier(n_estimators = 1300),threshold=\"mean\") # Feature selection\n",
        "sel.fit(x_train, y_train)\n",
        "features_to_rm = df.columns[np.where(sel.get_support() == False)]\n",
        "print(features_to_rm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Baseline (several classifiers were tested, RF performed best of those)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "clf = RandomForestClassifier(n_estimators=1300,random_state=0).fit(x_train, y_train)\n",
        "clf.score(x_test, y_test)\n",
        "# 0.618"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Parameter search 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "grid = {'max_depth': [1,3,5,10],\n",
        " 'max_features': ['auto'],\n",
        " 'min_samples_leaf': [1, 2, 4],\n",
        " 'min_samples_split': [2, 6, 10,],\n",
        " 'n_estimators' : [200,400,800,1200,2000]}\n",
        "\n",
        "rf_gs = GridSearchCV(estimator = RandomForestClassifier(), param_grid=grid, cv=6,verbose=1)\n",
        "rf_gs.fit(X,Y)\n",
        "print(rf_gs.best_params_)\n",
        "# {'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 200}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Parameter search 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "grid = {'max_depth': [5,7],\n",
        " 'max_features': ['auto'],\n",
        " 'min_samples_leaf': [1],\n",
        " 'min_samples_split': [8,10,20,100],\n",
        " 'n_estimators' : [200,300]}\n",
        "\n",
        "rf_gs = GridSearchCV(estimator = RandomForestClassifier(), param_grid=grid, cv=6,verbose=1)\n",
        "rf_gs.fit(X,Y)\n",
        "print(rf_gs.best_params_)\n",
        "# {'max_depth': 7, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 8, 'n_estimators': 300}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Training the classifier using found parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "rf = RandomForestClassifier(n_estimators=600, max_depth=7, min_samples_split=8,random_state=0)\n",
        "scores = cross_val_score(rf, X, Y, cv=10)\n",
        "print(\"%0.3f accuracy with a standard deviation of %0.3f\" % (scores.mean(), scores.std()))\n",
        "# 0.636 accuracy with a standard deviation of 0.053\n",
        "# n_est chosen to 600 after some short testing\n",
        "clf = rf.fit(X,Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creating output file consisting of predicted labels according to formatting instructions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_XVxBSwu3qUt"
      },
      "outputs": [],
      "source": [
        "ev = pd.read_csv (r'/content/EvaluateOnMe-edited.csv')\n",
        "ev = ev.drop(columns=[\"Unnamed: 0\"])\n",
        "ev = ev.drop(columns=['x1', 'x3', 'x7', 'x12', 'x13'])\n",
        "# print(ev)\n",
        "evData = ev.values\n",
        "\n",
        "predVal = clf.predict(evData)\n",
        "print(predVal)\n",
        "\n",
        "intToLabel = [\"Shoogee\", \"Bob\", \"Jorg\", \"Atsuto\"]\n",
        "predLabels = []\n",
        "for val in predVal:\n",
        "  predLabels.append(intToLabel[int(val)])\n",
        "\n",
        "print(predLabels)\n",
        "f = open(r'/content/temp.txt', \"w\")\n",
        "for label in predLabels:\n",
        "  f.write(label+'\\n')\n",
        "f.close()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "MLCHALLENGE.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
